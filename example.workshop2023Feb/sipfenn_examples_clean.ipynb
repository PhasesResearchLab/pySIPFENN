{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pySIPFENN MGF-PSU Workshop (Feb 2023)\n",
    "\n",
    "This Jupyter notebook is a brief walkthrough covering core functionalities of the **pySIPFENN** or **py**(**S**tructure-**I**nformed **P**rediction of **F**ormation **E**nergy using **N**eural **N**etworks) package; available through the PyPI repository. For a full up-to-date documentation, please refer to the [pySIPFENN GitHub repository](https://git.pysipfenn.org) or the [pySIPFENN documentation](https://pysipfenn.org). You can also find news about our projects using SIPFENN at our [Phases Research Lab](https://phaseslab.org) group website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"assets/neuralnetcolorized.png\" width=\"500\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install pySIPFENN\n",
    "\n",
    "Installing pySIPFENN is simple and easy utilizing either **PyPI** package repository or cloning from **GitHub**.\n",
    "While not required, it is recommended to first set up a virtual environment using venv or Conda. This ensures that\n",
    "one of the required versions of Python (3.9+) is used and there are no dependency conflicts. If you have Conda\n",
    "installed on your system ( [see miniconda instructions](https://docs.conda.io/en/latest/miniconda.html) ), you can create a new environment with:\n",
    "\n",
    "    conda create -n pysipfenn-workshop python=3.9 jupyter\n",
    "    conda activate pysipfenn-workshop\n",
    "\n",
    "And then simply install pySIPFENN from PyPI with\n",
    "\n",
    "    pip install pysipfenn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#!pip install pysipfenn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alternatively, you can also install pySIPFENN in editable mode if you cloned it from GitHub like\n",
    "\n",
    "    git clone https://github.com/PhasesResearchLab/pySIPFENN.git\n",
    "\n",
    "Or by downloading a ZIP file. Please note, this will by default download the latest development version of the\n",
    "software, which may not be stable. For a stable version, you can specify a version tag after the URL with\n",
    "`--branch <tag_name> --single-branch`.\n",
    "\n",
    "Then, move to the pySIPFENN folder and install in editable (`-e`) mode\n",
    "\n",
    "    cd pySIPFENN\n",
    "    pip install -e ."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting pySIPFENN\n",
    "\n",
    "To utilize pySIPFENN for straightforward calculations, **only the Calculator class is needed**. It allows for both fetching and identification of NN models and later running of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pysipfenn\n",
    "from pysipfenn import Calculator     # The only thing needed for calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "For pretty printing we also import pretty print Python built-in library. For convenience, we also import defaultdict from collections."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pprint import pprint            # pretty printing\n",
    "from collections import defaultdict  # convenience in the example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now initialize the Calculator. When run, this should display all models detected\n",
    "(e.g. âœ” SIPFENN_Krajewski2020 Standard Materials Model)\n",
    "and those not detected, but declared in the _modelsSIPFENN/models.json_ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Calculator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop, all models were made avaialble from the start, but on your machine, if this is the first run of pySIPFENN, no models will be available. However, one can easily fetch four default (as of Feb 2023) models from Zenodo with a simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c.downloadModels()\n",
    "#c.loadModels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of testing, a single model is sufficient and will be fetched faster. E.g. the lightweight model ('SIPFENN_Krajewski2020_NN24') can be acquired in about 1/30 of the time required to download all four."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c.downloadModels(network='SIPFENN_Krajewski2020_NN24')\n",
    "#c.loadModels()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In a typical scenario, everything would work smoothly, but in some cases you may not be allowed to write into pySIPFENN package directory. Last part of this workshop will cover how to work around this limitation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple run from directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest and most common usage of pySIPFENN is to deploy it on a directory/folder containing atomic structure files such as POSCAR or CIF. To of so, one simply specifies its location and which descriptor / feature vector should be used. The latter determines which ML models will be run, as they require a list of specific and ordered features as input. Furthermore, while the exact model can be specified by the user, by default all applicable models are run, as the run itself is 1-3 orders of magnitude faster than descriptor calculation.\n",
    "\n",
    "    c.runFromDirectory(directory='myInputFiles', descriptor='KS2022')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demonstration, a set of test files shipped with pySIPFENN under **directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#testFilesDir = \"pysipfenn/tests/testCaseFiles/exampleInputFiles/\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "is used. If you are using pySIPFENN in editable mode, you can simply use the above code to specify the directory. If you are using pySIPFENN from PyPI, you can use the following code to import test structures from the package."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from importlib import resources\n",
    "testFilesDir = resources.files('pysipfenn').joinpath('tests/testCaseFiles/exampleInputFiles/')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, feel free to change the directory to something with your structure files. Please note that the file extension (e.g. _.POSCAR_) is required for correct import and different types (POSCAR and CIF) can be mixed. Assuming you are in the workshop directory and you put something in the myInputFiles you can run the following"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#testFilesDir = 'myInputFiles'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, you can specify whether pySIPFENN should run in series or parallel **calculation mode**. The parallel mode is generally faster, but uses more system resources and may be slower on low-power machines with not enough CPU cores. Serial mode is also preferred if there are less than 5 calculations/worker due to multiprocessing overheads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.runFromDirectory(directory=testFilesDir,\n",
    "                   descriptor='KS2022',\n",
    "                   mode='serial');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all results are obtained and stored within the **c** Calculator object inside a few exposed conveniently named variables\n",
    "_predictions_ and _inputFiles_. Also, the descriptor data is retained in _descriptorData_ if needed. Let's look up the first 3 entries. Note that the unit of prediction will depend on the model used; in this case, it is eV/atom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(c.inputFiles[:3])\n",
    "pprint(c.predictions[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For user convenience, a few methods are provided for extracting the results. E.g., if pySIPFENN has been run from structure files, the _get_resultDictsWithNames()_ method is available to conveniently pass results forward in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.get_resultDictsWithNames()[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if results are to be preserved in a spreadsheet, they can be exported into a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.writeResultsToCSV('myFirstResults_pySIPFENN.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigma-Phase 5-sublattice model\n",
    "\n",
    "In the previous example we went over a set of POSCAR files in a directory without performing any non-automated manipulation. This is what authors expect will be the most common use pattern. However, pySIPFENN can be effortlessly combined with other structure analysis and manipulation software to fulfill more advanced needs. Here, as an example, we will play with a fairly complex **topologically close packed (TCP) phase called Sigma** possesing 5 chemically unique sites, which will be automatically identified from one configuration, like the one in figure below. Then we will look at energetics of all possible occupancies by 3 elements.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"assets/112-Cr12Fe10Ni8.png\" width=\"500\"/>\n",
    "</p>\n",
    "\n",
    " For structure manipulation we will utilize pymatgen Structure. The [Spglib library](spglib.github.io/spglib), accessed through pymatgen, will perform the symmetry analysis. We begin with import of appropriate modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.core import Structure\n",
    "from pymatgen.analysis.structure_analyzer import SpacegroupAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we take any end-member of the atomic structure in question. Conveniently, one of them is already in the test case files. Then we replace all species in it with dummy ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endMemberPath = resources.files('pysipfenn').joinpath('tests/testCaseFiles/exampleInputFiles/0-Cr8Fe18Ni4.POSCAR')\n",
    "baseStructure = Structure.from_file(endMemberPath)\n",
    "for el in set(baseStructure.species):\n",
    "    baseStructure.replace_species({el: 'dummy'})\n",
    "print(baseStructure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use Spglib to find and group unique chemical sites in the structure and lists of their equivalents. In the case of Sigma-phase, there are 5 such sites, also called **sublattices**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spgA = SpacegroupAnalyzer(baseStructure)\n",
    "eqAtoms = spgA.get_symmetry_dataset()['equivalent_atoms']\n",
    "uniqueDict = defaultdict(list)\n",
    "for site, unique in enumerate(eqAtoms):\n",
    "    uniqueDict[unique] += [site]\n",
    "pprint(uniqueDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with unique sites identified, we need to find all possible occupancies in the chemical system in question. Here we look at the Cr-Fe-Ni ternary. We expect 3^5=243 possible permutations with repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "allPermutations = list(product(['Fe', 'Cr', 'Ni'], repeat=5))\n",
    "print(f'Obtained {len(allPermutations)} permutations of the sublattice occupancy\\nE.g.:  {allPermutations[32]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structList = []\n",
    "for permutation in allPermutations:\n",
    "    tempStructure = baseStructure.copy()\n",
    "    for unique, el in zip(uniqueDict, permutation):\n",
    "        for site in uniqueDict[unique]:\n",
    "            tempStructure.replace(site, el)\n",
    "    structList.append(tempStructure)\n",
    "print(structList[32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Calculator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = c.runModels(structList=structList, descriptor='KS2022', mode='parallel', max_workers=6)\n",
    "pprint(predictions1[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = c.get_resultDicts()\n",
    "pprint(results1[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run models utilizing different descriptor / feature vector\n",
    "\n",
    "As alluded to before, pySIPFENN is built to enable rapid deployment of models based around single feature vector (or a subset of it) as descriptor calculation is by far the most costly component of structure-informed ML. However, the same feature vector cannot always be used and another one is required. There are generally three reasons for that:\n",
    "\n",
    "- The feature calculations are too slow / computationally expensive to be deployed on large scale (e.g. for 1,000,000 structures).\n",
    "- The descriptor does not include all the information needed to predict the property of interest well, or does not incorporate some dimension of the problem that is important for the prediction, e.g. the magnetic state or the volume.\n",
    "- We want to use a specific model that was trained on a different descriptor and retraining it is not feasible.\n",
    "\n",
    "In this part of the tutorial, we combine previous predictions with a models based on a different descriptor (Ward2017) used in the original SIPFENN paper and run 3 models trained on it. Notably, the KS2022 we already calcualted is an optimized subset of it, giving similar performance at a fraction of the cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = c.runModels(structList=structList, descriptor='Ward2017', mode='parallel', max_workers=6)\n",
    "pprint(predictions2[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = c.get_resultDicts()\n",
    "pprint(results2[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally combine two list of result dictionaries together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsCombined = [res1 | res2 for res1, res2 in zip(results1, results2)]\n",
    "pprint(resultsCombined[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsCombinedLabeled = [{'configuration': '-'.join(permutation)} | result for\n",
    "                          result, permutation in zip(resultsCombined, allPermutations)]\n",
    "pprint(resultsCombinedLabeled[31:33])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lastly, we can compare our results with the DFT reference data from the original paper. This was done in the SIPFENN paper [doi.org/10.1016/j.commatsci.2022.111254](https://doi.org/10.1016/j.commatsci.2022.111254) for the 3 models based on Ward2017. The NN30 is not optimized and is not plotted here.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"assets/SigmaSQS_plots.png\" width=\"1000\"/>\n",
    "</p>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a new model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a new model that accepts one of the descriptors / feature vectors implemented in pySIPFENN is very easy! No matter if it is a re-trained model to fit a specific set of species, or entirely new architecture. It doesn't even need to be created in PyTorch, as pySIPFENN imports ONNX format which can be the export target of almost all ML frameworks. For instance, models presented here were created in MxNet.\n",
    "\n",
    "To add your model, you just need to put it in the **modelsSIPFENN directory** in the pySIPFENN location and add a brief definition to the **models.json file**, with field name matching model file name, descriptive name, and specify which descriptor has been used. E.g.,:\n",
    "\n",
    "      \"SIPFENN_MyFunNet2023_NiSup\": {\n",
    "        \"name\": \"SIPFENN_Krajewski2022_NN30 re-optimized for Ni-superalloys\",\n",
    "        \"descriptor\": \"KS2022\",\n",
    "        \"note\": \"This is my new favorite model optimized for intermetallics in the Ni-based superalloys\"\n",
    "      }\n",
    "\n",
    "Then, you can just re-initialize the Calculator and everything should be loaded automatically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c = Calculator()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alternatively, like in the case of this workshop or some HPCs, you may not have direct write access to the pySIPFENN installation. In that case, you can add a model in your user directory and load it manually. To show that, we now copy one of pySIPFENN models to our working directory and re-name it to our liking ('SIPFENN_MyFunNet2023_NiSup')."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import shutil\n",
    "with open(resources.files('pysipfenn').joinpath('modelsSIPFENN/SIPFENN_Krajewski2022_NN30.onnx'), 'rb') as modelForTest:\n",
    "    with open('SIPFENN_MyFunNet2023_NiSup.onnx', 'wb') as modelForTestCopy:\n",
    "        shutil.copyfileobj(modelForTest, modelForTestCopy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And then load it manually."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "c.loadModelCustom(networkName='SIPFENN_MyFunNet2023_NiSup',\n",
    "                  modelName='SIPFENN_Krajewski2022_NN30 re-optimized for Ni-superalloys',\n",
    "                  descriptor='KS2022',\n",
    "                  modelDirectory='.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And then simply run everything as before."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3 = c.runModels(structList=structList, descriptor='KS2022', mode='parallel', max_workers=6)\n",
    "results3 = c.get_resultDicts()\n",
    "pprint(results3[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, append our new results to the previous ones!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsFull = [res12 | res3 for res12, res3 in zip(resultsCombinedLabeled, results3)]\n",
    "pprint(resultsFull[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Great job! You have successfully completed the workshop!\n",
    "Thank you for your attention! If you are following it in synchronous fashion, we will now head to Q&A session. If you are viewing it in your own time and have some questions, please feel free to reach out to [Adam M. Krajewski (ak@psu.edu)](ak@psu.edu) or [Zi-Kui Liu (zxl15@psu.edu)](zxl15@psu.edu)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
